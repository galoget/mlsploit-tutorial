summary: |
Machine learning (ML) has been used in many real-world applications.
However, recent research has shown that ML models can be highly vulnerable to adversarially examples, which are input instances that are intentionally designed to fool a model into producing a chosen prediction. 
The goal of this course is to study ML vulnerabilities andâ€¨develop secure AI in various domains, with the help of MLsploit.

MLsploit is an ML evaluation and fortification framework designed for education and research. It focuses on ML security related techniques in adversarial settings, such as adversarial creation, detection, and countermeasure. It consists of plug-able components or services which could demonstrate various security research topics.
MLsploit has a service-oriented architecture (SOA), a web portal to interact with users, and a RESTful API to automate the requests. The web portal is the main module to integrate various components through RESTful API with a defined JSON message. Each component can be implemented by any language on any platform with RESTful API supports. The components can be built as a serverless function or a micro-service wrapped into a portable container image. This flexible component design is agnostic to underlining ML module implementation and not lock-in to a specific cloud provider. MLsploit provides essential services to support cloud environments such as unique id, message queue, big data storage, and basic authentication.

Several built-in modules in MLsploit will be shown in this course, including defense in the image domain (Shield), malware detection and bypassing (AVPass, ELF, Barnum), and the application of Intel SGX for privacy-preserving and inference-preventing ML.

prerequisites:
  - "item 1"
  - "item 2"
